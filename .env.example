# API Keys for LLM services
MISTRAL_API_KEY=your_mistral_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Local LLM endpoint (if using local models)
LOCAL_LLM_URL=http://localhost:8000

# Embedding model settings
DEFAULT_EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DEVICE=cpu  # or 'cuda' for GPU

# Text processing settings
DEFAULT_CHUNK_SIZE=500
DEFAULT_CHUNK_OVERLAP=50
MAX_CONTEXT_DOCUMENTS=5

# FAISS settings
FAISS_INDEX_TYPE=FlatIP  # FlatIP, IVFFlat, etc.

# Web interface settings
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=localhost
