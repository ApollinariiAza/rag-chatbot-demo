#!/usr/bin/env python3
"""
Gradio –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è RAG Chatbot
–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ Streamlit —Å –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º
"""

import gradio as gr
import asyncio
import os
import tempfile
from pathlib import Path
import json
from datetime import datetime

from main import RAGChatbot
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —á–∞—Ç–±–æ—Ç–∞
chatbot_instance = None
chat_history = []

def init_chatbot(embedding_model="all-MiniLM-L6-v2", 
                llm_provider="mistral", 
                chunk_size=500):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Ç–±–æ—Ç–∞"""
    global chatbot_instance
    
    try:
        chatbot_instance = RAGChatbot(
            embedding_model=embedding_model,
            llm_provider=llm_provider,
            chunk_size=int(chunk_size)
        )
        return f"‚úÖ –ß–∞—Ç–±–æ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –º–æ–¥–µ–ª—å—é {embedding_model}"
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)}"

def process_documents(files, progress=gr.Progress()):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    global chatbot_instance
    
    if chatbot_instance is None:
        return "‚ùå –°–Ω–∞—á–∞–ª–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —á–∞—Ç–±–æ—Ç", ""
    
    if not files:
        return "‚ùå –§–∞–π–ª—ã –Ω–µ –≤—ã–±—Ä–∞–Ω—ã", ""
    
    temp_files = []
    processed_info = []
    
    try:
        progress(0, desc="–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤...")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        for i, file in enumerate(files):
            file_path = file.name
            temp_files.append(file_path)
            processed_info.append({
                'name': Path(file_path).name,
                'size': f"{os.path.getsize(file_path) / 1024:.1f} KB"
            })
            progress((i + 1) / len(files) * 0.3)
        
        progress(0.5, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        num_chunks = chatbot_instance.load_documents(temp_files)
        
        progress(1.0, desc="–ó–∞–≤–µ—Ä—à–µ–Ω–æ!")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        report = f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(files)} —Ñ–∞–π–ª–æ–≤\n"
        report += f"üìä –°–æ–∑–¥–∞–Ω–æ {num_chunks} —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤\n\n"
        report += "üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:\n"
        
        for info in processed_info:
            report += f"‚Ä¢ {info['name']} ({info['size']})\n"
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        total_docs = len(chatbot_instance.vector_store.documents)
        kb_stats = f"\nüìö –í—Å–µ–≥–æ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π: {total_docs} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤"
        
        return report + kb_stats, ""
        
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {str(e)}", ""

def chat_with_documents(message, history):
    """–ß–∞—Ç —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏"""
    global chatbot_instance, chat_history
    
    if chatbot_instance is None:
        response = "‚ùå –°–Ω–∞—á–∞–ª–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —á–∞—Ç–±–æ—Ç –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"
        history.append([message, response])
        return history, ""
    
    if len(chatbot_instance.vector_store.documents) == 0:
        response = "üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —á–∞—Ç–∞."
        history.append([message, response])
        return history, ""
    
    try:
        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        result = loop.run_until_complete(chatbot_instance.ask(message))
        loop.close()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
        response = result['answer']
        
        if result['sources']:
            response += "\n\nüìö **–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**\n"
            for i, source in enumerate(result['sources'][:3], 1):
                file_name = Path(source['source']).name
                response += f"{i}. *{file_name}* (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {source['score']:.2f})\n"
                response += f"   {source['content'][:100]}...\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        history.append([message, response])
        chat_history.append({
            'timestamp': datetime.now().isoformat(),
            'query': message,
            'answer': result['answer'],
            'sources': result['sources']
        })
        
        return history, ""
        
    except Exception as e:
        error_msg = f"‚ùå –û—à–∏–±–∫–∞: {str(e)}"
        history.append([message, error_msg])
        return history, ""

def clear_chat():
    """–û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞"""
    global chat_history
    chat_history = []
    return []

def get_knowledge_base_stats():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
    global chatbot_instance
    
    if chatbot_instance is None:
        return "‚ùå –ß–∞—Ç–±–æ—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
    
    num_docs = len(chatbot_instance.vector_store.documents)
    
    if num_docs == 0:
        return "üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞"
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    sources = {}
    file_types = {}
    
    for metadata in chatbot_instance.vector_store.metadata:
        if 'source' in metadata:
            source_name = Path(metadata['source']).name
            sources[source_name] = sources.get(source_name, 0) + 1
        
        if 'file_type' in metadata:
            file_type = metadata['file_type']
            file_types[file_type] = file_types.get(file_type, 0) + 1
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    stats = f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:**\n\n"
    stats += f"üìÑ –í—Å–µ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {num_docs}\n"
    stats += f"üìÅ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(sources)}\n\n"
    
    if sources:
        stats += "**–§–∞–π–ª—ã:**\n"
        for source, count in sorted(sources.items()):
            stats += f"‚Ä¢ {source}: {count} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤\n"
    
    if file_types:
        stats += "\n**–¢–∏–ø—ã —Ñ–∞–π–ª–æ–≤:**\n"
        for file_type, count in sorted(file_types.items()):
            stats += f"‚Ä¢ {file_type}: {count} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤\n"
    
    return stats

def export_chat_history():
    """–≠–∫—Å–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞"""
    global chat_history
    
    if not chat_history:
        return None, "üìù –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –ø—É—Å—Ç–∞"
    
    # –°–æ–∑–¥–∞–µ–º JSON —Å –∏—Å—Ç–æ—Ä–∏–µ–π
    export_data = {
        'export_timestamp': datetime.now().isoformat(),
        'total_messages': len(chat_history),
        'chat_history': chat_history
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
        json.dump(export_data, f, indent=2, ensure_ascii=False)
        temp_path = f.name
    
    return temp_path, f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(chat_history)} —Å–æ–æ–±—â–µ–Ω–∏–π"

def save_knowledge_base():
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
    global chatbot_instance
    
    if chatbot_instance is None:
        return None, None, "‚ùå –ß–∞—Ç–±–æ—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
    
    if len(chatbot_instance.vector_store.documents) == 0:
        return None, None, "üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞"
    
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        with tempfile.NamedTemporaryFile(delete=False) as f:
            base_path = f.name
        
        chatbot_instance.save_knowledge_base(base_path)
        
        pkl_path = base_path + '.pkl'
        faiss_path = base_path + '.faiss'
        
        message = f"‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ ({len(chatbot_instance.vector_store.documents)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤)"
        
        return pkl_path, faiss_path, message
        
    except Exception as e:
        return None, None, f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}"

def create_interface():
    """–°–æ–∑–¥–∞–Ω–∏–µ Gradio –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
    
    with gr.Blocks(title="RAG Chatbot Demo", theme=gr.themes.Soft()) as demo:
        
        gr.Markdown("""
        # ü§ñ RAG Chatbot Demo
        
        **Retrieval-Augmented Generation —á–∞—Ç–±–æ—Ç** - –∑–∞–≥—Ä—É–∂–∞–π—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –∑–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã!
        """)
        
        with gr.Tabs():
            
            # –í–∫–ª–∞–¥–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫
            with gr.TabItem("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏"):
                gr.Markdown("### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —á–∞—Ç–±–æ—Ç–∞")
                
                with gr.Row():
                    embedding_model = gr.Dropdown(
                        choices=["all-MiniLM-L6-v2", "all-mpnet-base-v2", "paraphrase-MiniLM-L6-v2"],
                        value="all-MiniLM-L6-v2",
                        label="–ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"
                    )
                    
                    llm_provider = gr.Dropdown(
                        choices=["mistral", "local"],
                        value="mistral",
                        label="–ü—Ä–æ–≤–∞–π–¥–µ—Ä LLM"
                    )
                    
                    chunk_size = gr.Slider(
                        minimum=200,
                        maximum=1000,
                        value=500,
                        step=50,
                        label="–†–∞–∑–º–µ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Ç–µ–∫—Å—Ç–∞"
                    )
                
                init_btn = gr.Button("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —á–∞—Ç–±–æ—Ç", variant="primary")
                init_status = gr.Textbox(label="–°—Ç–∞—Ç—É—Å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏", interactive=False)
                
                init_btn.click(
                    fn=init_chatbot,
                    inputs=[embedding_model, llm_provider, chunk_size],
                    outputs=[init_status]
                )
            
            # –í–∫–ª–∞–¥–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            with gr.TabItem("üìÑ –î–æ–∫—É–º–µ–Ω—Ç—ã"):
                gr.Markdown("### –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                
                file_upload = gr.Files(
                    label="–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª—ã (PDF, DOCX, TXT, PPTX)",
                    file_types=[".pdf", ".docx", ".doc", ".txt", ".md", ".pptx", ".ppt"]
                )
                
                process_btn = gr.Button("–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã", variant="primary")
                
                with gr.Row():
                    with gr.Column():
                        process_status = gr.Textbox(
                            label="–°—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏", 
                            interactive=False,
                            lines=10
                        )
                    
                    with gr.Column():
                        kb_stats = gr.Textbox(
                            label="–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π",
                            interactive=False,
                            lines=10
                        )
                
                process_btn.click(
                    fn=process_documents,
                    inputs=[file_upload],
                    outputs=[process_status, kb_stats]
                )
                
                # –ö–Ω–æ–ø–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                refresh_stats_btn = gr.Button("–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É")
                refresh_stats_btn.click(
                    fn=get_knowledge_base_stats,
                    outputs=[kb_stats]
                )
            
            # –ì–ª–∞–≤–Ω–∞—è –≤–∫–ª–∞–¥–∫–∞ —á–∞—Ç–∞
            with gr.TabItem("üí¨ –ß–∞—Ç", elem_id="chat-tab"):
                gr.Markdown("### –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º")
                
                chatbot = gr.Chatbot(
                    label="–†–∞–∑–≥–æ–≤–æ—Ä —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏",
                    height=400,
                    show_copy_button=True
                )
                
                msg = gr.Textbox(
                    label="–í–∞—à –≤–æ–ø—Ä–æ—Å",
                    placeholder="–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º...",
                    lines=2
                )
                
                with gr.Row():
                    submit_btn = gr.Button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å", variant="primary")
                    clear_btn = gr.Button("–û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç")
                
                submit_btn.click(
                    fn=chat_with_documents,
                    inputs=[msg, chatbot],
                    outputs=[chatbot, msg]
                )
                
                msg.submit(
                    fn=chat_with_documents,
                    inputs=[msg, chatbot],
                    outputs=[chatbot, msg]
                )
                
                clear_btn.click(
                    fn=clear_chat,
                    outputs=[chatbot]
                )
            
            # –í–∫–ª–∞–¥–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞
            with gr.TabItem("üíæ –≠–∫—Å–ø–æ—Ä—Ç"):
                gr.Markdown("### –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
                
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("**–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞**")
                        export_chat_btn = gr.Button("–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞")
                        chat_file = gr.File(label="–§–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞")
                        chat_export_status = gr.Textbox(label="–°—Ç–∞—Ç—É—Å —ç–∫—Å–ø–æ—Ä—Ç–∞", interactive=False)
                        
                        export_chat_btn.click(
                            fn=export_chat_history,
                            outputs=[chat_file, chat_export_status]
                        )
                    
                    with gr.Column():
                        gr.Markdown("**–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π**")
                        save_kb_btn = gr.Button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π")
                        
                        kb_pkl_file = gr.File(label="–§–∞–π–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π (.pkl)")
                        kb_faiss_file = gr.File(label="–§–∞–π–ª –∏–Ω–¥–µ–∫—Å–∞ (.faiss)")
                        kb_save_status = gr.Textbox(label="–°—Ç–∞—Ç—É—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è", interactive=False)
                        
                        save_kb_btn.click(
                            fn=save_knowledge_base,
                            outputs=[kb_pkl_file, kb_faiss_file, kb_save_status]
                        )
        
        # –§—É—Ç–µ—Ä —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        gr.Markdown("""
        ---
        **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:** PDF, DOCX, TXT, MD, PPTX  
        **–ú–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:** SentenceTransformers  
        **–í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î:** FAISS  
        **LLM:** Mistral API / –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
        """)
    
    return demo

def main():
    """–ó–∞–ø—É—Å–∫ Gradio –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    demo = create_interface()
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–ø—É—Å–∫–∞
    port = int(os.getenv('GRADIO_PORT', 7860))
    host = os.getenv('GRADIO_HOST', '127.0.0.1')
    
    print("–ó–∞–ø—É—Å–∫ RAG Chatbot —Å Gradio –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º...")
    print(f"–ê–¥—Ä–µ—Å: http://{host}:{port}")
    
    # –ó–∞–ø—É—Å–∫
    demo.launch(
        server_name=host,
        server_port=port,
        share=False,  # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ True –¥–ª—è –ø—É–±–ª–∏—á–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ —á–µ—Ä–µ–∑ Gradio tunnel
        show_error=True
    )

if __name__ == "__main__":
    main()